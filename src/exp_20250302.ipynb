{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itai/research/PersonalValuesGeometry/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from src.geometry import calcurate_concept_matrics_rank\n",
    "from src.utils.model_analysis import (\n",
    "    compute_inner_product_LOO,\n",
    "    get_concept_vector,\n",
    "    get_hidden_layer_n,\n",
    ")\n",
    "from src.utils.preprocess_data import get_counterfactual_pairs\n",
    "from src.utils.visualization import show_histogram_LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "dataset_type = \"valuenet\"\n",
    "concept_direction_type = \"pos2neg\"\n",
    "norm_type = \"base\"\n",
    "prompt_type = \"explicit_schwartz\"\n",
    "embedding_strategy = \"last\"\n",
    "device_id = 4\n",
    "concept_vectorize_strategy = \"embedding\"\n",
    "embedding_batch_size = 4\n",
    "target_layers = [i + 1 for i in range(28)]\n",
    "\n",
    "model_name = model_path.split(\"/\")[1].lower()\n",
    "num_sample = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.66it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(f\"cuda:{device_id}\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "num_hidden_layers: int = model.config.num_hidden_layers\n",
    "unembedding = model.lm_head.weight.detach()\n",
    "\n",
    "values_list_str: list[str] = [\n",
    "    line.strip()\n",
    "    for line in open(\"/home/itai/research/PersonalValuesGeometry/datasets/values.txt\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*===== Args =====*\n",
      "model_path='meta-llama/Llama-3.2-3B-Instruct'\n",
      "dataset_type='valuenet'\n",
      "concept_direction_type='pos2neg'\n",
      "norm_type='base'\n",
      "prompt_type='explicit_schwartz'\n",
      "embedding_strategy='last'\n",
      "target_layer=2\n",
      "num_sample=1000\n",
      "!concept_vectorize_strategy='embedding'\n",
      "*===============*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n*===== Args =====*\")\n",
    "print(f\"{model_path=}\")\n",
    "print(f\"{dataset_type=}\")\n",
    "print(f\"{concept_direction_type=}\")\n",
    "print(f\"{norm_type=}\")\n",
    "print(f\"{prompt_type=}\")\n",
    "print(f\"{embedding_strategy=}\")\n",
    "print(f\"{target_layer=}\")\n",
    "print(f\"{num_sample=}\")\n",
    "print(f\"!{concept_vectorize_strategy=}\")\n",
    "print(\"*===============*\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Random Pair] random文書pairを取得 ...\n"
     ]
    }
   ],
   "source": [
    "random_txt_path = f\"/home/itai/research/PersonalValuesGeometry/datasets/ValueNet/schwartz/random_pairs/{norm_type}/random_1000_pairs.txt\"\n",
    "# Random Pair\n",
    "print(\"[Random Pair] random文書pairを取得 ...\")\n",
    "# random_pairs = get_sequence_pairs(random_txt_path, int(num_sample))\n",
    "random_positive_sequences, random_negative_sequences = get_counterfactual_pairs(\n",
    "    random_txt_path, prompt_type=prompt_type, num_sample=int(num_sample)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Random Pair] positive文章のembeddingを計算 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing embeddings: 100%|██████████| 250/250 [01:55<00:00,  2.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_positive_embeddings[0]=tensor([ 0.0387, -0.0101,  0.0102,  ..., -0.0458, -0.0251,  0.0107])\n",
      "[Random Pair] negative文章のembeddingを計算 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing embeddings: 100%|██████████| 250/250 [01:58<00:00,  2.11batch/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"[Random Pair] positive文章のembeddingを計算 ...\")\n",
    "random_positive_embeddings = get_hidden_layer_n(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    sequences=random_positive_sequences,\n",
    "    n_layer=target_layer,\n",
    "    embedding_strategy=embedding_strategy,\n",
    "    batch_size=embedding_batch_size,\n",
    ")\n",
    "print(f\"{random_positive_embeddings[0]=}\")\n",
    "\n",
    "print(\"[Random Pair] negative文章のembeddingを計算 ...\")\n",
    "random_negative_embeddings = get_hidden_layer_n(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    sequences=random_negative_sequences,\n",
    "    n_layer=target_layer,\n",
    "    embedding_strategy=embedding_strategy,\n",
    "    batch_size=embedding_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_diff_embeddings = random_positive_embeddings - random_negative_embeddings\n",
    "random_diff_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0387, -0.0101,  0.0102,  ..., -0.0458, -0.0251,  0.0107],\n",
       "        [ 0.0387, -0.0101,  0.0102,  ..., -0.0458, -0.0251,  0.0107],\n",
       "        [ 0.0387, -0.0101,  0.0102,  ..., -0.0458, -0.0251,  0.0107],\n",
       "        ...,\n",
       "        [ 0.0387, -0.0101,  0.0102,  ..., -0.0458, -0.0251,  0.0107],\n",
       "        [ 0.0387, -0.0101,  0.0102,  ..., -0.0458, -0.0251,  0.0107],\n",
       "        [ 0.0387, -0.0101,  0.0102,  ..., -0.0458, -0.0251,  0.0107]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_positive_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA, PCA\n",
    "\n",
    "def apply_pca(embeddings: torch.Tensor, n_components=10):\n",
    "    \"\"\"Apply ICA to reduce dimensions of embeddings.\"\"\"\n",
    "    ica = PCA(n_components=n_components)\n",
    "    reduced_embeddings = ica.fit_transform(embeddings)\n",
    "    return torch.tensor(reduced_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied ICA to random positive embeddings\n",
      "applied ICA to random negative embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itai/research/PersonalValuesGeometry/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:789: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
      "/home/itai/research/PersonalValuesGeometry/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:789: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_random_positive_embeddings = apply_pca(random_positive_embeddings)\n",
    "print(\"applied ICA to random positive embeddings\")\n",
    "\n",
    "reduced_random_negative_embeddings = apply_pca(random_negative_embeddings)\n",
    "print(\"applied ICA to random negative embeddings\")\n",
    "\n",
    "reduced_random_diff_embeddings = reduced_random_positive_embeddings - reduced_random_negative_embeddings\n",
    "reduced_random_diff_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_random_positive_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
